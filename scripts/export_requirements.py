"""
Exports a generated_requirements.txt file.

Used for several purposes.

WARN: When upgrading the version of poetry used in the dockerfile and workflows,
ensure that this is still compatiable.
"""
import copy
import hashlib
import json
import os
import pathlib
import re
import textwrap

import tomli


GENERATED_FILE = pathlib.Path("requirements.txt")
CONSTRAINTS_FILE = pathlib.Path("modmail/constraints.txt")
DOC_REQUIREMENTS = pathlib.Path("docs/.requirements.txt")

VERSION_RESTRICTER_REGEX = re.compile(r"(?P<sign>[<>=!]{1,2})(?P<version>\d+\.\d+?)(?P<patch>\.\d+?|\.\*)?")
PLATFORM_MARKERS_REGEX = re.compile(r'sys_platform\s?==\s?"(?P<platform>\w+)"')

PACKAGE_REGEX = re.compile(r"^[^=<>~]+")
# fmt: off
MESSAGE = textwrap.indent(textwrap.dedent(
    f"""
    NOTICE: This file is automatically generated by scripts/{__file__.rsplit('/',1)[-1]!s}
    This is also automatically regenerated when an edit to pyproject.toml or poetry.lock is commited.
    """
), '# ').strip()
# fmt: on


def check_hash(hash: str, content: dict) -> bool:
    """Check that the stored hash from the metadata file matches the pyproject.toml file."""
    # OG source: https://github.com/python-poetry/poetry/blob/fe59f689f255ea7f3290daf635aefb0060add056/poetry/packages/locker.py#L44 # noqa: E501
    # This code is as verbatim as possible, with a few changes to be non-object-oriented.

    _relevant_keys = ["dependencies", "dev-dependencies", "source", "extras"]

    def get_hash(content: dict) -> str:
        """Returns the sha256 hash of the sorted content of the pyproject file."""
        content = content["tool"]["poetry"]

        relevant_content = {}
        for key in _relevant_keys:
            relevant_content[key] = content.get(key)

        content_hash = hashlib.sha256(json.dumps(relevant_content, sort_keys=True).encode()).hexdigest()

        return content_hash

    return hash == get_hash(content)


def _write_file(path: os.PathLike, contents: str, skip_if_identical: bool = True) -> bool:
    """
    Write to a supplied file.

    If skip_if_equal is True, will not write if the contents will not change. (Default: True)
    """
    path = pathlib.Path(path)
    if path.exists():
        with open(path, "r") as f:
            if contents == f.read():
                # nothing to edit
                return False

    with open(path, "w") as f:
        f.write(contents)
        return True


def _extract_packages_from_requirements(requirements: str) -> "tuple[set[str],list[str]]":
    """Extract a list of packages from the provided requirements str."""
    req = requirements.split("\n")
    packages = set()
    for i, line in enumerate(req.copy()):
        if line.startswith("#"):
            continue
        if not len(line.strip()):
            continue

        # requirement files we will be parsing can have `;` or =<>~
        match = PACKAGE_REGEX.match(line)
        if match is None:
            continue
        # replace the line with the match
        req[i] = match[0].strip()

        # replacing `_` with `-` because pypi treats them as the same character
        # poetry is supposed to do this, but does not always
        package = req[i].lower().replace("_", "-")

        packages.add(package)

    return packages, req


def _update_versions_in_requirements(requirements: "list[str]", packages: dict) -> str:
    """Update the versions in requirements with the provided package to version mapping."""
    for i, package in enumerate(requirements.copy()):
        if package.startswith("#"):
            continue
        if not len(package.strip()):
            continue
        try:
            requirements[i] = package + "==" + packages[package.lower().replace("_", "-")]
        except KeyError:
            raise AttributeError(f"{package} could not be found in poetry.lock") from None
    return "\n".join(requirements)


def _export_doc_requirements(toml: dict, file: pathlib.Path, *packages) -> int:
    """
    Export the provided packages versions.

    Return values:
    0 no changes
    1 exported new requirements
    2 file does not exist
    3 invalid packages
    """
    file = pathlib.Path(file)
    if not file.exists():
        # file does not exist
        return 2

    with open(file) as f:
        contents = f.read()

    # parse the packages out of the requirements txt
    packages, req = _extract_packages_from_requirements(contents)

    # get the version of each package
    packages_metadata: dict = toml["package"]
    new_versions = {
        package["name"]: package["version"]
        for package in packages_metadata
        if package["name"].lower().replace("_", "-") in packages
    }

    try:
        new_contents = _update_versions_in_requirements(req, new_versions)
    except AttributeError as e:
        print(e)
        return 3
    if new_contents == contents:
        # don't write anything, just return 0
        return 0

    with open(file, "w") as f:
        f.write(new_contents)

    return 1


def export(
    req_path: os.PathLike,
    should_validate_hash: bool = True,
    *,
    include_markers: bool = True,
    export_doc_requirements: bool = True,
) -> int:
    """Read and export all required packages to their pinned version in requirements.txt format."""
    req_path = pathlib.Path(req_path)

    with open("pyproject.toml") as f:
        pyproject = tomli.load(f)

    with open("poetry.lock") as f:
        lockfile = tomli.load(f)

    # check hashes
    if should_validate_hash and not check_hash(lockfile["metadata"]["content-hash"], pyproject):
        print("The lockfile is out of date. Please run 'poetry lock'")
        return 2

    pyproject_deps = pyproject["tool"]["poetry"]["dependencies"]

    main_deps = {}
    for package in lockfile["package"]:
        if package["category"] == "main":
            main_deps[package["name"]] = package

    # NOTE: git dependencies are not supported. If a source requires git, this will fail.
    # NOTE: python versions that matter with the platform are not calculated right now
    req_txt = MESSAGE + "\n" * 2
    dependency_lines = {}
    to_add_markers = {}
    for dep in main_deps.values():
        line = ""
        if (pyproject_dep := pyproject_deps.get(dep["name"], None)) is not None and hasattr(
            pyproject_dep, "get"
        ):
            if pyproject_dep.get("git", None) is not None:
                raise NotImplementedError("git sources are not supported")

            elif pyproject_dep.get("url", None) is not None:
                line += " @ " + pyproject_dep["url"]
            else:
                line += "=="
                line += dep["version"]
        else:
            line += "=="
            line += dep["version"]

        if include_markers:
            if (pyvers := dep["python-versions"]) != "*":
                # TODO: add support for platform and python combined version markers
                line += " ; "
                final_version_index = pyvers.count(", ")
                for count, version in enumerate(pyvers.split(", ")):
                    match = VERSION_RESTRICTER_REGEX.match(version)

                    if (patch := match.groupdict().get("patch", None)) is not None and not patch.endswith(
                        "*"
                    ):
                        version_kind = "python_full_version"
                    else:
                        version_kind = "python_version"

                    patch = patch if patch is not None else ""
                    patch = patch if not patch.endswith("*") else ""
                    line += version_kind + " "
                    line += match.group("sign") + " "
                    line += '"' + match.group("version") + patch + '"'
                    line += " "
                    if count < final_version_index:
                        line += "and "

            if (dep_deps := dep.get("dependencies", None)) is not None:

                for k, v in copy.copy(dep_deps).items():
                    if hasattr(v, "get") and v.get("markers", None) is not None:
                        pass
                    else:
                        del dep_deps[k]
                if len(dep_deps):
                    to_add_markers.update(dep_deps)

        dependency_lines[dep["name"]] = line

    if include_markers:
        # add the sys_platform lines
        # platform markers only matter based on what requires the dependency
        # in order to support these properly, they have to be added to an already existing line
        # for example, humanfriendly requires pyreadline on windows only,
        # so sys_platform == win needs to be added to pyreadline
        for k, v in to_add_markers.items():
            line = dependency_lines[k]
            markers = PLATFORM_MARKERS_REGEX.match(v["markers"])
            if markers is not None:
                if ";" not in line:
                    line += " ; "
                elif "python_" in line or "sys_platform" in line:
                    line += "and "
                line += 'sys_platform == "' + markers.group("platform") + '"'
            dependency_lines[k] = line

    req_txt += "\n".join(sorted(k + v.rstrip() for k, v in dependency_lines.items())) + "\n"

    if export_doc_requirements:
        exit_code = _export_doc_requirements(lockfile, DOC_REQUIREMENTS)
    else:
        exit_code = 0

    if req_path.exists():
        with open(req_path, "r") as f:
            if req_txt == f.read():
                # nothing to edit
                # if exit_code is ever removed from here, this should return zero
                return exit_code

    if _write_file(req_path, req_txt):
        print(f"Updated {req_path} with new requirements.")
        return 1
    else:
        print(f"No changes were made to {req_path}")
        return 0


def main(path: os.PathLike, include_markers: bool = True, **kwargs) -> int:
    """Export a requirements.txt and constraints.txt file."""
    if not include_markers:
        path = path or CONSTRAINTS_FILE
    kwargs["include_markers"] = include_markers
    return export(path, **kwargs)


if __name__ == "__main__":
    import argparse
    import sys

    parser = argparse.ArgumentParser(description="Export requirements to requirements.txt")
    parser.add_argument(
        "--ignore-hash",
        dest="skip_hash_check",
        action="store_true",
        default=False,
        help="Skip checking if the poetry.lock file is up to date with changes in pyproject.toml",
    )

    parser.add_argument(
        "-o",
        "--output",
        dest="output_file",
        default=GENERATED_FILE,
        help="File to export to.",
    )
    parser.add_argument(
        "--docs",
        action="store_true",
        dest="export_doc_requirements",
        default=False,
        help="Also export the documentation requirements. Defaults to false.",
    )

    args = parser.parse_args()
    # I am aware that the second method will only run if the first method returns 0. This is intended.
    sys.exit(
        main(
            args.output_file,
            should_validate_hash=not args.skip_hash_check,
            export_doc_requirements=args.export_doc_requirements,
        )
        or main(CONSTRAINTS_FILE, include_markers=False, should_validate_hash=not args.skip_hash_check)
    )
